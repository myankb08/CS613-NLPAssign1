{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13618559,"sourceType":"datasetVersion","datasetId":8654739},{"sourceId":13622708,"sourceType":"datasetVersion","datasetId":8657850},{"sourceId":13624990,"sourceType":"datasetVersion","datasetId":8659539}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install essential libraries for deep learning, model loading, and evaluation\n!pip install torch --quiet\n!pip install transformers==4.53.2 --quiet\n!pip install datasets==2.18.0 --quiet\n!pip install evaluate==0.4.1 --quiet\n!pip install sacrebleu==2.4.2 --quiet\n!pip install pandas --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T15:32:54.249456Z","iopub.execute_input":"2025-11-05T15:32:54.249719Z","iopub.status.idle":"2025-11-05T15:34:38.034089Z","shell.execute_reply.started":"2025-11-05T15:32:54.249698Z","shell.execute_reply":"2025-11-05T15:34:38.033119Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.2.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Install the custom toolkit required for IndicTrans2 pre-processing and post-processing\n!pip install indictranstoolkit --quiet","metadata":{"execution":{"iopub.status.busy":"2025-11-05T15:34:38.035624Z","iopub.execute_input":"2025-11-05T15:34:38.035913Z","iopub.status.idle":"2025-11-05T15:34:42.412109Z","shell.execute_reply.started":"2025-11-05T15:34:38.035883Z","shell.execute_reply":"2025-11-05T15:34:42.411453Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m546.1/546.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\n# Access the stored Hugging Face token from Kaggle Secrets\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\n# Programmatically log in to Hugging Face\nlogin(token=hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T15:34:42.412988Z","iopub.execute_input":"2025-11-05T15:34:42.413215Z","iopub.status.idle":"2025-11-05T15:34:43.098154Z","shell.execute_reply.started":"2025-11-05T15:34:42.413192Z","shell.execute_reply":"2025-11-05T15:34:43.097630Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\n# Define the device for computation (GPU if available, otherwise CPU)\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nLANGS = [\"hin_Deva\", \"tel_Telu\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T15:34:43.099540Z","iopub.execute_input":"2025-11-05T15:34:43.099746Z","iopub.status.idle":"2025-11-05T15:34:46.585141Z","shell.execute_reply.started":"2025-11-05T15:34:43.099729Z","shell.execute_reply":"2025-11-05T15:34:46.584340Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nMODEL_NAME = \"ai4bharat/indictrans2-indic-indic-dist-320M\"\n\n# Load the tokenizer\n# trust_remote_code is required for custom tokenization logic\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n\n# Load the model\n# trust_remote_code is required for custom model architecture\n# torch_dtype=torch.float16 uses half-precision for memory efficiency and speed\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    MODEL_NAME,\n    trust_remote_code=True,\n).to(DEVICE)\n\nmodel.eval() # Set the model to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T15:34:46.585849Z","iopub.execute_input":"2025-11-05T15:34:46.586193Z","iopub.status.idle":"2025-11-05T15:35:16.437925Z","shell.execute_reply.started":"2025-11-05T15:34:46.586174Z","shell.execute_reply":"2025-11-05T15:35:16.437144Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8fd7ff0b3934853a0185585d5ede096"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenization_indictrans.py:   0%|          | 0.00/8.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3827526bb68842b8b0a9cd8730021f82"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n- tokenization_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"dict.SRC.json:   0%|          | 0.00/3.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e01fe385baf044a78373c943fb147576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dict.TGT.json:   0%|          | 0.00/3.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"037e84c22e444551a314ec508a4ff1d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.SRC:   0%|          | 0.00/3.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c69fe4f68484e8096952b5132c79ec7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a7b6e6442dd43ff992cd1bc64bf310e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf4818503a30425ebcabe1f86159bac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_indictrans.py:   0%|          | 0.00/14.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c103633d42cd48dc8ba41089cb25c33b"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n- configuration_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_indictrans.py:   0%|          | 0.00/79.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d7b6c97a7ec46e18cc938c64c5af1c1"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n- modeling_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n2025-11-05 15:34:58.606395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762356898.827170      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762356898.880549      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8275939197c4dacbe6c4e9e6e0d4374"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7baf03bc751249dc8ba2429dc1631607"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"IndicTransForConditionalGeneration(\n  (model): IndicTransModel(\n    (encoder): IndicTransEncoder(\n      (embed_tokens): Embedding(122706, 512, padding_idx=1)\n      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-17): 18 x IndicTransEncoderLayer(\n          (self_attn): IndicTransAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): IndicTransDecoder(\n      (embed_tokens): Embedding(122672, 512, padding_idx=1)\n      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-17): 18 x IndicTransDecoderLayer(\n          (self_attn): IndicTransAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): IndicTransAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=122672, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from IndicTransToolkit.processor import IndicProcessor\n\n# Instantiate the processor for inference tasks\nip = IndicProcessor(inference=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T15:35:16.438686Z","iopub.execute_input":"2025-11-05T15:35:16.439212Z","iopub.status.idle":"2025-11-05T15:35:17.058846Z","shell.execute_reply.started":"2025-11-05T15:35:16.439193Z","shell.execute_reply":"2025-11-05T15:35:17.058271Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def translate_docs(docs, src_lang, tgt_lang):\n    translations = []\n    for idx, doc in enumerate(docs):\n        try:\n            # Use preprocess_batch for batch of one\n            preprocessed = ip.preprocess_batch([doc], src_lang=src_lang, tgt_lang=tgt_lang)\n            if not preprocessed:\n                print(f\"Skipping empty doc at index {idx}\")\n                translations.append(\"\")\n                continue\n        except Exception as e:\n            print(f\"Preprocessing error for index {idx}: {e}\")\n            translations.append(\"\")\n            continue\n        \n        inputs = tokenizer(preprocessed, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n        forced_bos_token_id = tokenizer.convert_tokens_to_ids(f\"<2{tgt_lang}>\")\n        with torch.no_grad():\n            generated = model.generate(\n                **inputs,\n                num_beams=5,\n                max_length=2048,  # Use higher if doc is large\n                forced_bos_token_id=forced_bos_token_id\n            )\n        decoded = tokenizer.batch_decode(generated, skip_special_tokens=True)\n        try:\n            # Use postprocess_batch for batch of one\n            postprocessed = ip.postprocess_batch(decoded, lang=tgt_lang)\n            translations.append(postprocessed[0] if postprocessed else decoded[0])\n        except Exception as e:\n            print(f\"Postprocessing error for index {idx}: {e}\")\n            translations.append(decoded[0])\n    return translations\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T15:35:17.059577Z","iopub.execute_input":"2025-11-05T15:35:17.059840Z","iopub.status.idle":"2025-11-05T15:35:17.066081Z","shell.execute_reply.started":"2025-11-05T15:35:17.059810Z","shell.execute_reply":"2025-11-05T15:35:17.065374Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\n# Load dataset CSV with columns: 'hin_Deva', 'tel_Telu'\ndf = pd.read_csv('/kaggle/input/coi-hin-tel/COI_hin_tel - Sheet1.csv')\n\n# Translate Telugu to Hindi\ntel_docs = df['tel_Telu'].tolist()    # Telugu documents for translation\ntranslated_hindi = translate_docs(tel_docs, src_lang='tel_Telu', tgt_lang='hin_Deva')\ndf['trans_hindi'] = translated_hindi\n\n# Translate Hindi to Telugu\nhin_docs = df['hin_Deva'].tolist()    # Hindi documents for translation\ntranslated_telugu = translate_docs(hin_docs, src_lang='hin_Deva', tgt_lang='tel_Telu')\ndf['trans_telugu'] = translated_telugu\n\n\n# Save results to CSV\ndf.to_csv('/kaggle/working/hindi_telugu_translated_coi.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T15:35:17.066927Z","iopub.execute_input":"2025-11-05T15:35:17.067319Z","iopub.status.idle":"2025-11-05T15:38:23.235903Z","shell.execute_reply.started":"2025-11-05T15:35:17.067294Z","shell.execute_reply":"2025-11-05T15:38:23.235118Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from sacrebleu.metrics import CHRF\nimport pandas as pd\n\ndef evaluatedirection(srclang, tgtlang, dataset):\n    \"\"\"\n    Evaluate translation quality for src to tgt given the dataset.\n    srclang, tgtlang are column names in the dataset.\n    dataset is a DataFrame with references for tgtlang.\n    \"\"\"\n    # Extract source sentences and target reference sentences\n    srcsentences = dataset[srclang].tolist()\n    tgtsentences = dataset[tgtlang].tolist()\n    \n    # Translate source sentences (using your translation function)\n    preds = translate_docs(srcsentences, src_lang=srclang, tgt_lang=tgtlang)\n    \n    # Flatten preds if needed\n    preds = [p if isinstance(p, str) else p[0] for p in preds]\n    if len(preds) == 0:\n        print(f\"No predictions produced for {srclang}-{tgtlang}\")\n        return None\n    \n    # Calculate chrF score\n    chrf = CHRF(word_order=2)\n    score = chrf.corpus_score(preds, tgtsentences).score\n    return score\n\n# Load your dataset CSV with reference column names\ndf = pd.read_csv('/kaggle/input/coi-hin-tel/COI_hin_tel - Sheet1.csv')\n\n# Evaluate Hindi to Telugu translation quality\nscore_hindi_telugu = evaluatedirection('hin_Deva', 'tel_Telu', df)\nprint(f\"chrF Hindi->Telugu: {score_hindi_telugu:.2f}\")\n\n# Evaluate Telugu to Hindi translation quality\nscore_telugu_hindi = evaluatedirection('tel_Telu', 'hin_Deva', df)\nprint(f\"chrF Telugu->Hindi: {score_telugu_hindi:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T15:38:23.236770Z","iopub.execute_input":"2025-11-05T15:38:23.237254Z","iopub.status.idle":"2025-11-05T15:41:27.685311Z","shell.execute_reply.started":"2025-11-05T15:38:23.237232Z","shell.execute_reply":"2025-11-05T15:41:27.684634Z"}},"outputs":[{"name":"stdout","text":"chrF Hindi->Telugu: 1.48\nchrF Telugu->Hindi: 0.68\n","output_type":"stream"}],"execution_count":10}]}